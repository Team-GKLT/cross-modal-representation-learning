{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66757c27",
   "metadata": {},
   "source": [
    "# This notebook is used for extracting feature embeddings from the recipe text - NetID:  gg676, xl598, vt152, smk371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c796f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from ast import literal_eval\n",
    "import glob\n",
    "import os\n",
    "import pyarrow\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9504c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first json from the recipe text containing title, ingredients, id, instructions\n",
    "with open('/common/home/gg676/536/data/text_data/layer1.json', 'r') as fp:\n",
    "    data_1 = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af850a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second json from the recipe text containing the mapping b/w text id and image id(s)\n",
    "with open('/common/home/gg676/536/data/text_data/layer2.json', 'r') as fp:\n",
    "    data_2 = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am creating a map using dictionary to make it run in constant time b/w text id and image id\n",
    "data_3 = {}\n",
    "for i in data_2:\n",
    "    data_3[i['id']] = [os.path.splitext(j['id'])[0] for j in i['images']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d006628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get ids of images from the id that we saved already from the image dataset\n",
    "def load_ids(path):\n",
    "    id_list = []\n",
    "    id_dict = {}\n",
    "    for i in glob.glob(path+'/*'):\n",
    "        data = torch.load(i)\n",
    "        id_list.extend(data)\n",
    "    id_dict = dict.fromkeys(id_list)\n",
    "    return id_dict\n",
    "id_dict = load_ids('/common/home/gg676/536/data/ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all the text data that belong to either train, validation or test using the image id as reference\n",
    "# I have already created a split data of image features along with their id\n",
    "def prepare_df(data_1, data_2, id_dict):\n",
    "    title_list = []\n",
    "    ingredients_list = []\n",
    "    instructions_list = []\n",
    "    combined_list = []\n",
    "    img_id_list = []\n",
    "    id_list = []\n",
    "    count = 0\n",
    "    for item in data_1:\n",
    "        flag = 0\n",
    "        try:\n",
    "            data_3[item['id']]\n",
    "            for img_id in data_3[item['id']]:\n",
    "\n",
    "                title_sent = \"\"\n",
    "                ingredients_sent = \"\"\n",
    "                instructions_sent = \"\"\n",
    "\n",
    "                title_sent = title_sent + item['title']\n",
    "                for i in item['ingredients']:\n",
    "                    ingredients_sent = ingredients_sent + i['text']\n",
    "                for i in item['instructions']:\n",
    "                    instructions_sent = instructions_sent + i['text']\n",
    "                title_list.append(title_sent)\n",
    "                ingredients_list.append(ingredients_sent)\n",
    "                instructions_list.append(instructions_sent)\n",
    "                combined_list.append(title_sent + ingredients_sent + instructions_sent)\n",
    "                img_id_list.append(img_id)\n",
    "                id_list.append(item['id'])\n",
    "        except KeyError:\n",
    "                pass\n",
    "            \n",
    "        if count % 10000 == 0:\n",
    "            print(count)\n",
    "            \n",
    "        count += 1\n",
    "    #print(title_sent + ingredients_sent + instructions_sent)\n",
    "    df = pd.DataFrame(zip(id_list, img_id_list, title_list, ingredients_list, instructions_list, combined_list), columns=['id', 'img_id', 'title', 'ingredients', 'instructions', 'combined'])\n",
    "    return df\n",
    "\n",
    "df = prepare_df(data_1, data_2, id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeca728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get both ids and features extracted from the image dataset.\n",
    "#This is required because we will create a datafrane that can be merged with the text data to make sure the ids match\n",
    "#by using left join\n",
    "def load_data(path):\n",
    "    data_list = []\n",
    "\n",
    "    for i in glob.glob(path+'/*'):\n",
    "        x = torch.load(i)\n",
    "        data_list.extend(x)\n",
    "    return data_list\n",
    "id_list = load_data('/common/home/gg676/536/data/ids/')\n",
    "feature_list = load_data('/common/home/gg676/536/data/features/')\n",
    "df_image = pd.DataFrame(zip(id_list, feature_list), columns=['img_id', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f328832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join wrt image id to make sure only the ones that match with the \n",
    "df_merged = pd.merge(df_image, df, how='left', on='img_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5145f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is done to tokenize each of title, ingredients, instructions and combined and store as pickle    \n",
    "def prepare_df(data):\n",
    "    title_list = []\n",
    "    ingredients_list = []\n",
    "    instructions_list = []\n",
    "    combined_list = []\n",
    "    id_list = []\n",
    "    for item in data:\n",
    "        title_sent = \"\"\n",
    "        ingredients_sent = \"\"\n",
    "        instructions_sent = \"\"\n",
    "\n",
    "        title_sent = title_sent + item['title']\n",
    "        for i in item['ingredients']:\n",
    "            ingredients_sent = ingredients_sent + i['text']\n",
    "        for i in item['instructions']:\n",
    "            instructions_sent = instructions_sent + i['text']\n",
    "        title_list.append(title_sent)\n",
    "        ingredients_list.append(ingredients_sent)\n",
    "        instructions_list.append(instructions_sent)\n",
    "        combined_list.append(title_sent + ingredients_sent + instructions_sent)\n",
    "        id_list.append(item['id'])\n",
    "    #print(title_sent + ingredients_sent + instructions_sent)\n",
    "    df = pd.DataFrame(zip(id_list, title_list, ingredients_list, instructions_list, combined_list), columns=['id', 'title', 'ingredients', 'instructions', 'combined'])\n",
    "    return df    \n",
    "def apply_tokenize(data, tokenizer, field_name):\n",
    "    data[field_name] = data.apply(lambda row: tokenizer(row[field_name], max_length=512, padding='max_length', truncation=True), axis=1)\n",
    "    return data\n",
    "\n",
    "def parallelize_dataframe(df, tokenizer, func, field_name):\n",
    "    df_split = np.array_split(df, 8)\n",
    "    pool = Pool(8)\n",
    "    df = pd.concat(pool.map(func, df_split, tokenizer, field_name))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "    \n",
    "def tokenize_data(df, tokenizer, field_no):\n",
    "    counter = 0\n",
    "    id_list = []\n",
    "    img_id_list = []\n",
    "    result_list = []\n",
    "    start = time.time()\n",
    "    #print(type(field_name))\n",
    "    for row in df.itertuples():\n",
    "        #result_list = df.apply(lambda row: tokenizer(row[field_name], max_length=512, padding='max_length', truncation=True), axis=1)\n",
    "        img_id_list.append(row.img_id)\n",
    "        id_list.append(row.id)\n",
    "        result_list.append(tokenizer(row[field_no], max_length=512, padding='max_length', truncation=True))\n",
    "        if counter % 100000 == 0:\n",
    "            print(counter)\n",
    "        counter += 1\n",
    "    return id_list, img_id_list, result_list#df_res\n",
    "\n",
    "def save_data(data, path, file_name):\n",
    "    with open(path+file_name, 'wb') as fp:\n",
    "        pickle.dump(data, fp)\n",
    "\n",
    "def main():\n",
    "    #input_path = 'C:/535/text_data/layer1.json'\n",
    "    output_path ='/common/home/gg676/536/data/text_data/'\n",
    "    #data = read_data(input_path)\n",
    "    #df = prepare_df(data)\n",
    "    #del data\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    col_pos_list = [4, 5, 6, 7]\n",
    "    output_file_name_list = ['title', 'ingredients', 'instructions', 'combined']\n",
    "    \n",
    "    for idx, col_name in enumerate(output_file_name_list):\n",
    "        print(\"idx: \", idx)\n",
    "        start = time.time()\n",
    "        id_list, img_id_list, result_list = tokenize_data(df_merged, tokenizer, col_pos_list[idx])\n",
    "        print(\"Time Taken: \", time.time()-start)\n",
    "        #df_res = parallelize_dataframe(df[:100], tokenizer, apply_tokenize, col_name)\n",
    "        save_data(id_list, output_path, \"id_col_\"+col_name)\n",
    "        save_data(img_id_list, output_path, \"img_id_col_\"+col_name)\n",
    "        save_data(result_list, output_path, \"result_col_\"+col_name)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afef780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(file_name):\n",
    "    with open('/common/home/gg676/536/data/text_data/'+file_name, 'rb') as fp:\n",
    "        x_data = pickle.load(fp)\n",
    "    return x_data\n",
    "\n",
    "x_data = load_pickle_data('result_col_combined')\n",
    "x_id = load_pickle_data('id_col_combined')\n",
    "df_x_data = pd.DataFrame(x_data)\n",
    "x_input_id = df_x_data['input_ids']\n",
    "x_attn_mask = df_x_data['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10022ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "#for param in model.bert.parameters():\n",
    "#    param.requires_grad = False\n",
    "model.eval()\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(torch.cuda.device_count(), \"GPUs!\")\n",
    "  model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ae8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, input_ids, attn_mask):\n",
    "        self.id = ids\n",
    "        #self.title = [tokenizer(text, max_length=512, padding='max_length', truncation=True) for text in df['title']]\n",
    "        #self.ingredients = [tokenizer(text, max_length=512, padding='max_length', truncation=True) for text in df['ingredients']]\n",
    "        #self.instructions = [tokenizer(text, max_length=512, padding='max_length', truncation=True) for text in df['instructions']]\n",
    "        self.input_ids = input_ids\n",
    "        self.attn_mask = attn_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id)\n",
    "    \n",
    "    def get_batch_texts(self, idx):\n",
    "        return self.id[idx], torch.tensor(self.input_ids[idx]), torch.tensor(self.attn_mask[idx])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #batch_id, batch_input_ids, batch_attn_mask = torch.tensor(self.get_batch_texts(idx))\n",
    "        return self.id[idx], torch.tensor(self.input_ids[idx]), torch.tensor(self.attn_mask[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82412dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(x_id, x_input_id, x_attn_mask)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, num_workers=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc849f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(path, file_name, data):\n",
    "    torch.save(data, path+file_name)\n",
    "    \n",
    "def extract_features(model, dataloader):\n",
    "    start = time.time()\n",
    "    feature_list = []\n",
    "    id_list = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch_data in enumerate(dataloader):\n",
    "            if idx % 4096 == 0:\n",
    "                print(idx)\n",
    "            batch_id, batch_input_ids, batch_attn_mask = batch_data\n",
    "            #print(type(torch.Tensor(batch_input_ids)))\n",
    "            batch_input_ids, batch_attn_mask = torch.from_numpy(np.asarray(batch_input_ids)).to('cuda'), torch.from_numpy(np.asarray(batch_attn_mask)).to('cuda')\n",
    "            #batch_data = batch_data.to('cuda')\n",
    "            outputs = model(batch_input_ids, batch_attn_mask)\n",
    "            #print(outputs[0].shape)\n",
    "            #hidden_states = outputs[0][:, 0]\n",
    "            #print(hidden_states.shape)\n",
    "            #break\n",
    "            sent_embed = torch.stack(hidden_states[-4:]).sum(0)\n",
    "            sent_embed = torch.mean(word_embed, dim=1)\n",
    "            feature_list.extend(sent_embed.detach().cpu())\n",
    "            id_list.extend(batch_id)\n",
    "        print(\"Time taken: \", time.time() - start)\n",
    "    return id_list, feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_list, feature_list = extract_features(model, dataloader)\n",
    "save_features('/common/home/gg676/536/data/text_data/results/', 'combined_id.pth', ids_list)\n",
    "save_features('/common/home/gg676/536/data/text_data/results/', 'combined_features.pth', feature_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
